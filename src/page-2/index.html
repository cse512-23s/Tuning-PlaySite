<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Visualization with D3.js</title>
    <style>
        /* CSS styling */
        .chart {
            display: block;
            margin: auto;
            height: 500px;
            width: 500px;
        }

        .axis path,
        .axis line {
            fill: none;
            stroke: #000;
            shape-rendering: crispEdges;
        }

        #chart3 {
            height: 500px;
            width: 500px;
            margin: auto;
        }
        
    </style>
</head>
<body>
    <h3>2. Choose Batch Size</h2>
    <div id="chart" class="chart"></div>
    <p>By keeping all hyperparameters the same, increasing batch size increases validation accuracy.</p>

    <!-- Second Chart -->
    <div id="chart2"></div>
    <p>But by using the best hyperparameters for individual batch sizes, we can see that there is no effect of increasing batch size on performance.</p>
    <p>Any batch size works but configurations of other hyperparameters like an epoch, optimizer, and regularizer change with batch size. So chose a single batch size for tuning all other hyperparameters.</p>

    <!-- Third Chart -->
    <div id="chart3"></div>
    
    
    <script src="https://d3js.org/d3.v7.js"></script>
    <script src="script.js"></script>
    <p>In theory, the steps needed are halved for each doubling batch size. But in practice, it gets linear after a particular batch size. So, choose the largest available batch size for faster training and experiments.</p>

</body>
</html>
