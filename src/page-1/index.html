<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        h1, h2, h3 {
            color: #333;
        }
        a {
            color: #007BFF;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        ol {
            padding-left: 1.5em;
        }
        ol li {
            padding: 0.5em 0;
        }
        .highlight {
            color: #007BFF;
        }
    </style>
</head>
<body>
    <h1>Understanding and Tuning Hyperparameters in Machine Learning</h1>

    <p>Hyperparameters are configuration settings that are external to the machine learning model itself and need to be manually set before the training process begins. Setting/tuning these hyperparameters is extremely difficult for several reasons. There are large number of hyperparameters, and each hyperparameter can take on multiple values. One hyperparameter can affect another, thus understanding the complex dependencies requires a lot of experimentation which many can’t afford as tuning them is time-consuming and expensive. Worst of all there is no universal solution, as one set of hyperparameters won’t work for a different problem/model. So we provide a comprehensive approach to this problem. To know more about hyperparameters refer to this <a href="https://www.javatpoint.com/hyperparameters-in-machine-learning">link</a>.</p>


    <h2>Tuning Strategy:</h2>
    <p>Start with a problem statement and query the necessary data and make it ready (cleaning) for the model training.</p>

    <h2>Strategy to tune hyperparameters:</h2>
    <ol>
      <li>Identify an appropriately-scoped goal for the next round of experiments.</li>
      <li>Design and run a set of experiments that makes progress towards this goal.</li>
      <li>Learn what we can from the results.</li>
      <li>Consider whether to launch the new best configuration.</li>
    </ol>
    <h2>Tuning Steps:</h2>
    <h3>1. Start with a model configuration</h2>

    <p>Model architectures typically have various hyperparameters that determine the model's size and other details (e.g. number of layers, layer width, type of activation function). Start with small models and grow eventually. Try to choose standard model configuration, so one doesn’t have to spend a lot of time tuning model hyper-parameters. Choose a starting optimizer, epoch, and performance metrics.</p>
</body>
</html>
